{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\python311\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in c:\\python311\\lib\\site-packages (from statsmodels) (1.26.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\python311\\lib\\site-packages (from statsmodels) (1.11.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in c:\\python311\\lib\\site-packages (from statsmodels) (2.1.3)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\python311\\lib\\site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\davis\\appdata\\roaming\\python\\python311\\site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\davis\\appdata\\roaming\\python\\python311\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\davis\\appdata\\roaming\\python\\python311\\site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: linearmodels in c:\\python311\\lib\\site-packages (5.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\python311\\lib\\site-packages (from linearmodels) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\python311\\lib\\site-packages (from linearmodels) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\python311\\lib\\site-packages (from linearmodels) (1.11.3)\n",
      "Requirement already satisfied: statsmodels>=0.12.0 in c:\\python311\\lib\\site-packages (from linearmodels) (0.14.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4 in c:\\python311\\lib\\site-packages (from linearmodels) (1.0.0)\n",
      "Requirement already satisfied: Cython>=0.29.37 in c:\\python311\\lib\\site-packages (from linearmodels) (3.0.8)\n",
      "Requirement already satisfied: pyhdfe>=0.1 in c:\\python311\\lib\\site-packages (from linearmodels) (0.2.0)\n",
      "Requirement already satisfied: formulaic>=0.6.5 in c:\\python311\\lib\\site-packages (from linearmodels) (1.0.1)\n",
      "Requirement already satisfied: setuptools-scm[toml]<9.0.0,>=8.0.0 in c:\\python311\\lib\\site-packages (from linearmodels) (8.0.4)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in c:\\python311\\lib\\site-packages (from formulaic>=0.6.5->linearmodels) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python311\\lib\\site-packages (from formulaic>=0.6.5->linearmodels) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in c:\\python311\\lib\\site-packages (from formulaic>=0.6.5->linearmodels) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\davis\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.3.0->linearmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas>=1.3.0->linearmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas>=1.3.0->linearmodels) (2023.3)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\davis\\appdata\\roaming\\python\\python311\\site-packages (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (23.2)\n",
      "Requirement already satisfied: setuptools in c:\\python311\\lib\\site-packages (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (65.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\python311\\lib\\site-packages (from statsmodels>=0.12.0->linearmodels) (0.5.6)\n",
      "Requirement already satisfied: six in c:\\users\\davis\\appdata\\roaming\\python\\python311\\site-packages (from patsy>=0.5.4->statsmodels>=0.12.0->linearmodels) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['true_weight_check_cw2'] = np.where((df['pdp'] == 1) & (df['basic'] == 1), df['true_weight_check_cw'], np.nan)\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['idd'] = df.groupby('new_id1').cumcount() + 1\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'C{i}_plan_weight2'] = (df.groupby('new_id1')['idd'].transform(lambda x: x == i)).astype(int)\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'C{i}_weight2'] = df['true_weight_check_cw2'] * df[f'C{i}_plan_weight2']\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'C{i}_plan_weight2'] = (df.groupby('new_id1')['idd'].transform(lambda x: x == i)).astype(int)\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'C{i}_weight2'] = df['true_weight_check_cw2'] * df[f'C{i}_plan_weight2']\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'C{i}_plan_weight2'] = (df.groupby('new_id1')['idd'].transform(lambda x: x == i)).astype(int)\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'C{i}_weight2'] = df['true_weight_check_cw2'] * df[f'C{i}_plan_weight2']\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'C{i}_plan_weight2'] = (df.groupby('new_id1')['idd'].transform(lambda x: x == i)).astype(int)\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'C{i}_weight2'] = df['true_weight_check_cw2'] * df[f'C{i}_plan_weight2']\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['conc_weig_basicpdpd_c4'] = sum(df[f'C{i}_weight2'] for i in range(1, 5))\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['enrol_tot_share'] = np.where((df['enrol_tot_num'] != 0) & pd.notnull(df['enrol_tot_num']) & (df['enrol_tot_denominator'] != 0) & pd.notnull(df['enrol_tot_denominator']),\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['firm_tot_share'] = df.groupby(['new_id1', 'Parent_Organization'])['enrol_tot_share'].transform('sum')\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['iddd'] = df.groupby(['new_id1', 'Parent_Organization']).cumcount() + 1\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['temp2'] = (df.groupby('new_id1')['iddd'].transform('min') == df['iddd']).astype(int)\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['num_firms'] = df.groupby('new_id1')['temp2'].transform('sum')\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['firm_tot_share2'] = np.where(df['temp2'] == 1, df['firm_tot_share'], np.nan)\n",
      "C:\\Users\\Davis\\AppData\\Local\\Temp\\ipykernel_14668\\371290269.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['hershf_firm_tot'] = df.groupby('new_id1')['firm_tot_share2'].transform(lambda x: ((x ** 2).sum() - (1 / df['num_firms'])) / (1 - (1 / df['num_firms'])))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Run regressions for each set of controls and print summaries\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, controls \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(control_sets, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mrun_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogmean_w_reg_bpr_ch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconc_weig_basicpdpd_c4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Summary:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39msummary(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_iv_regression\u001b[39m(df, dependent, endog, exog, instrument):\n",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m, in \u001b[0;36mrun_regression\u001b[1;34m(df, dependent, independent, controls, interaction_terms)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m interaction_terms:\n\u001b[0;32m     80\u001b[0m         formula \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m * \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mterm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 81\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(cov_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m, cov_kwds\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregionid\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:229\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         design_info \u001b[38;5;241m=\u001b[39m design_info\u001b[38;5;241m.\u001b[39msubset(cols)\n\u001b[0;32m    225\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_idx\u001b[39m\u001b[38;5;124m'\u001b[39m: missing_idx,\n\u001b[0;32m    226\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m: missing,\n\u001b[0;32m    227\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula\u001b[39m\u001b[38;5;124m'\u001b[39m: formula,  \u001b[38;5;66;03m# attach formula for unpckling\u001b[39;00m\n\u001b[0;32m    228\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesign_info\u001b[39m\u001b[38;5;124m'\u001b[39m: design_info})\n\u001b[1;32m--> 229\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m mod\u001b[38;5;241m.\u001b[39mformula \u001b[38;5;241m=\u001b[39m formula\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# since we got a dataframe, attach the original\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:923\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    921\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    922\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 923\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:748\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    750\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    751\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:202\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRegressionModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:132\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# detect where the constant is\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     check_implicit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     exog_max \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(exog_max)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexog contains inf or nans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[0;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2698\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "%pip install statsmodels\n",
    "%pip install linearmodels\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from linearmodels.iv import IV2SLS\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\Davis\\Downloads\\paper.dta'\n",
    "df = pd.read_stata(file_path)\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame loaded with the necessary data\n",
    "\n",
    "# Part I: Generate market shares and C4 for LIS Weights for BASIC PDP\n",
    "df['true_weight_check_cw2'] = np.where((df['pdp'] == 1) & (df['basic'] == 1), df['true_weight_check_cw'], np.nan)\n",
    "df.sort_values(by='true_weight_check_cw2', ascending=False, inplace=True)\n",
    "df['idd'] = df.groupby('new_id1').cumcount() + 1\n",
    "\n",
    "for i in range(1, 5):\n",
    "    df[f'C{i}_plan_weight2'] = (df.groupby('new_id1')['idd'].transform(lambda x: x == i)).astype(int)\n",
    "    df[f'C{i}_weight2'] = df['true_weight_check_cw2'] * df[f'C{i}_plan_weight2']\n",
    "\n",
    "df['conc_weig_basicpdpd_c4'] = sum(df[f'C{i}_weight2'] for i in range(1, 5))\n",
    "df.drop(columns=['idd'] + [f'C{i}_weight2' for i in range(1, 5)] + [f'C{i}_plan_weight2' for i in range(1, 5)], inplace=True)\n",
    "\n",
    "# Part II: Controls - Generate HHI by Firm\n",
    "df['enrol_tot_share'] = np.where((df['enrol_tot_num'] != 0) & pd.notnull(df['enrol_tot_num']) & (df['enrol_tot_denominator'] != 0) & pd.notnull(df['enrol_tot_denominator']),\n",
    "                                 df['enrol_tot_num'] / df['enrol_tot_denominator'], 0)\n",
    "df['firm_tot_share'] = df.groupby(['new_id1', 'Parent_Organization'])['enrol_tot_share'].transform('sum')\n",
    "df['iddd'] = df.groupby(['new_id1', 'Parent_Organization']).cumcount() + 1\n",
    "df['temp2'] = (df.groupby('new_id1')['iddd'].transform('min') == df['iddd']).astype(int)\n",
    "df['num_firms'] = df.groupby('new_id1')['temp2'].transform('sum')\n",
    "df['firm_tot_share2'] = np.where(df['temp2'] == 1, df['firm_tot_share'], np.nan)\n",
    "df['hershf_firm_tot'] = df.groupby('new_id1')['firm_tot_share2'].transform(lambda x: ((x ** 2).sum() - (1 / df['num_firms'])) / (1 - (1 / df['num_firms'])))\n",
    "df.drop(columns=['iddd', 'temp2', 'firm_tot_share2'], inplace=True)\n",
    "\n",
    "# Get the sample right before proceeding\n",
    "df.drop_duplicates(subset=['regionid', 'year'], keep='last', inplace=True)\n",
    "df.dropna(subset=['regionid', 'year'], inplace=True)\n",
    "\n",
    "# Part III: Dependent Variable and Other Covariates\n",
    "df.sort_values(by=['regionid', 'year'], inplace=True)\n",
    "df['logmean_w_reg_bpr'] = np.log(df['mean_w_reg_basprem'])\n",
    "df['logmean_w_reg_bpr_ch'] = df.groupby('regionid')['logmean_w_reg_bpr'].diff()\n",
    "\n",
    "df['change'] = df['year'] > 2008\n",
    "df['laghershf_firm_tot'] = df.groupby('regionid')['hershf_firm_tot'].shift(1)\n",
    "df['lagunemploymentrate'] = df.groupby('regionid')['unemploymentrate'].shift(1)\n",
    "\n",
    "# Dropping year == 2006 for regression analysis\n",
    "df_filtered = df[df['year'] != 2006]\n",
    "\n",
    "\n",
    "# Generate a binary variable for year 2009\n",
    "df['year2009'] = np.where(df['year'] > 2008, 1, 0)\n",
    "\n",
    "# Create interaction term for year2009 and mapd_regio_2006share\n",
    "df['regio_2006share2'] = df['mapd_regio_2006share'] * df['year2009']\n",
    "\n",
    "# Compute the change in the log of mean weighted reg bpr\n",
    "df['logmean_w_reg_bpr'] = np.log(df['mean_w_reg_basprem'])\n",
    "df.sort_values(by=['regionid', 'year'], inplace=True)\n",
    "df['logmean_w_reg_bpr_ch'] = df.groupby('regionid')['logmean_w_reg_bpr'].shift(-1) - df['logmean_w_reg_bpr']\n",
    "\n",
    "# Add lagged variables\n",
    "df['laghershf_firm_tot'] = df.groupby('regionid')['hershf_firm_tot'].shift(1)\n",
    "df['lagunemploymentrate'] = df.groupby('regionid')['unemploymentrate'].shift(1)\n",
    "\n",
    "def run_regression(df, dependent, independent, controls, interaction_terms=None):\n",
    "    formula = f\"{dependent} ~ {' + '.join([independent] + controls)}\"\n",
    "    if interaction_terms:\n",
    "        for term in interaction_terms:\n",
    "            formula += f\" * {term}\"\n",
    "    model = smf.ols(formula, data=df).fit(cov_type='cluster', cov_kwds={'groups': df['regionid']})\n",
    "    return model\n",
    "\n",
    "# Example controls from the Stata code (simplified for demonstration)\n",
    "control_sets = [\n",
    "    [\"conc_weig_basicpdpd_c4\"],\n",
    "    [\"conc_weig_basicpdpd_c4\"] + [f\"ttrend{i}\" for i in range(1, 35)],\n",
    "    [\"conc_weig_basicpdpd_c4\", \"laghershf_firm_tot\", \"lagunemploymentrate\"],\n",
    "    [\"conc_weig_basicpdpd_c4\", \"laghershf_firm_tot\", \"lagunemploymentrate\"] + [f\"ttrend{i}\" for i in range(1, 35)],\n",
    "    [\"conc_weig_basicpdpd_c4\", \"laghershf_firm_tot\",  \"lagunemploymentrate\", \"mean_weig_reg_vintage\" \"mean_weig_reg_pharmacies\", \"mean_weig_reg_drugs\"],\n",
    "    [\"conc_weig_basicpdpd_c4\", \"laghershf_firm_tot\",  \"lagunemploymentrate\", \"mean_weig_reg_vintage\" \"mean_weig_reg_pharmacies\", \"mean_weig_reg_drugs\"] + [f\"ttrend{i}\" for i in range(1, 35)]\n",
    "]\n",
    "\n",
    "# Run regressions for each set of controls and print summaries\n",
    "for index, controls in enumerate(control_sets, start=1):\n",
    "    model = run_regression(df, \"logmean_w_reg_bpr_ch\", \"conc_weig_basicpdpd_c4\", controls)\n",
    "    print(f\"Model {index} Summary:\\n\", model.summary(), \"\\n\\n\")\n",
    "\n",
    "def run_iv_regression(df, dependent, endog, exog, instrument):\n",
    "    iv_formula = f\"{dependent} ~ 1 + {exog} + [{endog} ~ {instrument}]\"\n",
    "    iv_model = IV2SLS.from_formula(iv_formula, data=df).fit(cov_type='clustered', clusters=df['regionid'])\n",
    "    return iv_model\n",
    "\n",
    "# Example IV regression with specified controls\n",
    "iv_controls = [\"laghershf_firm_tot\", \"lagunemploymentrate\"]  # Simplified for demonstration\n",
    "iv_model = run_iv_regression(df, \"logmean_w_reg_bpr_ch\", \"conc_weig_basicpdpd_c4\", \" + \".join(iv_controls), \"regio_2006share2\")\n",
    "print(\"IV Model Summary:\\n\", iv_model.summary)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
